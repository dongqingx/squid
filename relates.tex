\section{Related Works}
A significant amount of prior work has been done protecting the privacy of network datasets.
We summarize them here and clarify our privacy goals in this paper. 

\textbf{Syntactic Privacy.}~~Early works on privacy-preserving network publishing mainly focus on developing anonymization techniques for deterministic graphs. They are designed to \emph{publish} the data in an anonymized manner without making any assumptions of the type of analysis and queries that will be executed on the release one. Once the data is published, it is available for any type of analysis. Most of them leverage \emph{syntactic} privacy models derived from $k$-anonymity~\cite{Sweeney:2002:KAM:774544.774552} to create $k$ identical neighborhoods, or $k$ identical degree nodes. Following this path, many graph anonymization techniques have been proposed.

\textbf{Graph Anonymization Techniques.}~~Existing methods for anonymizing ``graphs" can be classified into four main categories: (1) Clustering-based generalization~\cite{Hay_Anonymizing_2007,Bhagat_Class_2009,hay2010resisting}; (2)~{\em Edge modification}~\cite{Liu_Towards_2008, Zhou_Preserving_2008, Wang2011, Wu_k_2010, Skarkala_Privacy_2012}, 
(3)~{\em Edge randomization}~\cite{Liu_Privacy_2009,Ying_Randomizing_2008, Ninggal_Utility_2015},
and~(4)~{\em Uncertainty semantic-based modifications} which add uncertainty to some edges and thus converting the graph to an uncertain version~\cite{Boldi_Injecting_2012, Nguyen_Anonymizing_2015}. The uncertainty semantic-based approaches transform the original deterministic graph into an uncertain one to be published. These techniques are known as the state-of-art ones because of their excellent privacy-utility tradeoff brought by the fine-grained perturbation leveraging the uncertain semantics. To the best of our knowledge, these techniques are tailored to \emph{deterministic} graphs (unweighted \& weighted) that overlook edge uncertainty.  

\textbf{Diffiential Privacy.}~~Another avenue is to apply differential privacy to provide privacy guarantee for network data. It roughly falls into two directions. The first direction aims to release certain differentially private \emph{data mining results}, such as degree distributions, sub-graph counts, and frequent graph patterns. Such methods that release only query results require tracking the results: early uses of the data can affect the quality of later uses, thus no new queries can be permitted on the data. For example, the purpose here is to let researchers develop new algorithms. It is unclear how this can be done without access to network data. The second direction aims to publish a sanitized graph. Most research in this direction projects an input graph to dK-series and ensures differential privacy on dK-series statistics. These private statistics are then either fed into generators or MCMC process to generate a fit Syntactic graphs. While current techniques are still inadequate to provide desirable data utility for many graph mining tasks. 

\textbf{Our Goal: Data Model \&~Privacy Policy.}~~
In this work, we study the problem of privacy preserving \emph{uncertain} graph publishing. Conceptually, the problem can be interpreted as a natural generalization of the \emph{determinitic} graph contexts to a larger probabilistic context, with the anonymization process being specifically optimized. 

Here, we remind the reader the approach that first casting the probability of every edge into a weight then applies existing anonymization methods on this weighted graph to attain the anonymized uncertain graph is problematic. First, there is no meaningful way to perform such casting. The casting has been proven to be erroneous in various uncertain graph mining tasks~\cite{Potamias_K_2010,Zhao_Detecting_2014}. Second, there is no principled way to additionally encode normal weights on the edge. For example, each link in the road network can be weighted indicating the distance or travel time between them, and a probability can be assigned to model the likelihood of a traffic jam~\cite{Jin_Distance_2011}. In summary, existing strategies for weighted graphs anonymization cannot be applied to \emph{uncertain} graphs.

In the context of privacy preserving graph publishing, we can choose to adopt the Syntactic or differential privacy policy.
$\epsilon$-differential privacy does relate to individual identifiability and provides strong privacy guarantee without making any assumption of privacy risks. However, there is no clear way to set a general policy for a value $\epsilon$ that provides sufficient privacy~\cite{lee2011}. In contrast to $\epsilon$-differential privacy, Syntactic privacy model can generally be defined and understood based on the data schema; parameters have a clear privacy meaning that can be understood independent of the actual data and have a clear relationship to the legal concept of individual identifiability of data. In this work, we choose $k$-obfuscation, a variant of $k$-anonymity as the basis of our privacy policy for uncertain graph \emph{publishing}.

% Add more sentence to uncertain graphs ... 
% Our general approach is to produce Syntactic graphs by adding controlled perturbations to the structure of the original \emph{uncertain graph}. The generic approach can provide protection against identity disclosure and link disclosure. The choice directly impacts how much structural noise must be introduced to obtain a given level of privacy guarantees. In this paper, we chose to target against node re-identification problem for {\emph uncertain graph} releasing.  