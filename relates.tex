\section{Related Works}
A significant amount of prior work has been done on protecting the privacy of network datasets.
The .... is out of the scope of this paper. Here, we just ..... 
% We summarize them here and clarify our privacy goals in this paper. 

\textbf{Syntactic Privacy.}~~Early works on privacy-preserving network publishing (PPNP) focus on developing anonymization techniques. Many of them modify the graph structure in subtle ways that guarantee privacy but keep much of graph structure.  The released graph is available for various graph analysis tasks. These approaches generally provide protection against specific de-anonymization attacks. Most of them leverage syntactic privacy models derived from $k$-anonymity~\cite{Sweeney:2002:KAM:774544.774552}. It requires creating $k$ identical neighborhoods, or $k$ identical degree nodes to blend victims. 

Existing graph anonymization methods can be classified into four main categories: (1) Clustering-based generalization~\cite{Hay_Anonymizing_2007,Bhagat_Class_2009,hay2010resisting}; (2)~{\em Edge modification}~\cite{Liu_Towards_2008, Zhou_Preserving_2008, Wang2011, Wu_k_2010, Skarkala_Privacy_2012}, 
(3)~{\em Edge randomization}~\cite{Liu_Privacy_2009,Ying_Randomizing_2008, Ninggal_Utility_2015},
and~(4)~{\em Uncertainty semantic-based modifications} which add uncertainty to some edges and thus converting the deterministic graph to an uncertain version~\cite{Boldi_Injecting_2012, Nguyen_Anonymizing_2015}. The uncertainty semantic-based approaches are known as the state-of-art ones because of their excellent privacy-utility trade-off, brought by the fine-grained perturbation leveraging the uncertain semantics. 

 
\textbf{Differential Privacy.}~~Another option is to apply $\epsilon$-differential privacy for providing privacy guarantee. It roughly falls into two directions. The first direction aims to release certain differentially private mining results, such as degree distributions, sub-graph counts, and frequent graph patterns~\cite{Xiao_Differentially_2014,Day:2016}. These methods only release query result, early uses of the data can affect the quality of later uses. What's worse, no new queries can be permitted on the data. The second direction aims to share the meaningful graph~\cite{Sala_Sharing_2011}. Most research in this direction projects an input graph to dK-series and ensures differential privacy on dK-series statistics. Later, private statistics are then either fed into generators or MCMC process to generate a fit synthetic graphs. While current techniques are still inadequate to provide desirable data utility for many graph mining tasks. 

\emph{All the methods target at providing privacy guarantee for the deterministic graph. The uncertain scenario is overlooked.}

\vspace{-5pt}
\subsection{Our Privacy Goal}
\vspace{-2.5pt}

Our work seeks a solution to share meaningful uncertain graphs while preserving privacy.
As ever discussed, direct applying existing PPNP schemes leads to poor result because of the disregarding or miscasting edge uncertainties. We believe the anonymization process needed to be specifically optimized. In this paper, we try to move this line of research one step forward from the deterministic context to a larger probabilistic context.  And, we choose $k$-obfuscation, a variant of $k$-anonymity, as the privacy notion of uncertain graph sharing. 

There is a widespread belief that differential privacy and its offsprings are immune to various privacy attacks. It offers a guarantee bound $\epsilon$ on loss of privacy due to the data release~\cite{Sala_Sharing_2011,Xiao_Differentially_2014}. In fact, it is becoming a gold standard of privacy. However, there is no clear way to set a general policy for choosing a privacy parameter $\epsilon$ for sufficient privacy guarantee~\cite{lee2011}. Its implications and impacts on the risk of disclosure in practice heavy depends on data detail. Thus, differential privacy is difficult to apply in practice. 

In contrast, the notion of syntactic privacy can generally be defined and understood based on the data schema. And, its parameters have a clear privacy meaning that can be understood independent of the actual data. Moreover, they have a clear relationship to the legal concept of individual identifiability. 
