\section{Related Works}
A significant amount of prior work has been done protecting privacy of network datasets.
We summarize them here and clarify our privacy goals in this project. 

\textbf{Graph Anonymization.}~ Early works on privacy-preserving network data publishing mainly focus on developing anonymization techniques for deterministic graphs against specific types of de-anonymization attacks. Most of them employ privacy models derived from $k$-anonymity. XXX 


\textbf{Diffiential Privacy.}~ The recent research on applying differential privacy to network data roughly falls into two directions. The first direction aims to release certain differentially private data mining results, such as degree distributions, sub-graph counts and frequent graph patterns. XXXXX--XXXXX. 
The second direction aims to publish a sanitized graph. Most research in this direction projects an input graph to dK-series and ensures differential privacy on dK-series statistics. These private statistics are then either fed into generators or MCMC process to generate a fit synthetic graphs. While, current techniques are still inadequate to provide desirable data utility for many graph mining tasks. 



\textbf{Our Goals:Privacy Model \& Data Model}~
Syntactic privacy model can generally be defined and understood based on the data schema; parameters have a clear privacy meaning that can be understood independent of the actual data and have a clear relationship to the legal concept of individual identifiability of data. On the other hand, $$-differential privacy does relate to individual identifiability, the privacy parameter does not have such a clear relation. There is no clear way to set a general policy for a value $$ that provides sufficient privacy. Thus, we choose XXX. 

Our general approach is to produce synthetic graphs by adding controlled perturbations to the structure of the original \emph{uncertain graph}. The generic approach can provide protection against identity disclosure and link disclosure. The choice directly impacts how much structural noise must be introduced to obtain a given level of privacy guarantees. In this paper, we chose to target against node re-identification problem for {\emph uncertain graph} releasing because XXXX. 